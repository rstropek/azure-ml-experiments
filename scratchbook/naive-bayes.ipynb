{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Cuisine Type Prediction Sample\r\n",
        "\r\n",
        "## Data Source\r\n",
        "\r\n",
        "The sample data was taken from *kaggle*'s [*What's Cooking*](https://www.kaggle.com/c/whats-cooking/overview) competition."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Training Data\r\n",
        "\r\n",
        "We read some JSON training data using [*pandas*](https://pandas.pydata.org/). It contains ingrediences of sample recipies and corresponding cuisine types (e.g. *greek*, *german*)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "train_json = pd.read_json(\"./train.json\")\r\n",
        "train_json.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614151070328
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_json['ingredients']\r\n",
        "df = train_json['ingredients']\r\n",
        "# df[df.apply(lambda s: len(s) == 1 and s[0] == 'water')].index\r\n",
        "train_json['id'][df[df.apply(lambda s: len(s) == 1 and s[0] == 'water')].index]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614151070430
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\r\n",
        "nltk.download('wordnet')\r\n",
        "\r\n",
        "from nltk import WordNetLemmatizer\r\n",
        "lemmatizer = WordNetLemmatizer()\r\n",
        "\r\n",
        "actual = lemmatizer.lemmatize('bats')\r\n",
        "assert actual == 'bat', f'Lemmatizing did not work, received \"{actual}\"'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614151072472
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean Data\n",
        "For our data to be usable we clean it by stripping off unnecessary words and characters, \n",
        "as well as lemmatizing to get the ingredients' stems. All that is done in our preprocess function."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\r\n",
        "import unidecode\r\n",
        "\r\n",
        "def preprocess(ingredients):\r\n",
        "    ingredients_text = ' '.join(ingredients)\r\n",
        "    ingredients_text = ingredients_text.lower() #Lower - Casing\r\n",
        "    ingredients_text = ingredients_text.replace('-', ' ') # Removing Hyphen\r\n",
        "    words = []\r\n",
        "    for word in ingredients_text.split():\r\n",
        "        word = re.sub(\"[0-9]\",\" \",word) # removing numbers,punctuations and special characters\r\n",
        "        word = re.sub((r'\\b(oz|ounc|ounce|pound|lb|inch|inches|kg|to)\\b'), ' ', word) # Removing Units\r\n",
        "        if len(word) <= 2: continue # Removing words with less than two characters\r\n",
        "        word = unidecode.unidecode(word) # Removing accents\r\n",
        "        word = lemmatizer.lemmatize(word) # Lemmatize\r\n",
        "        if len(word) > 0: words.append(word)\r\n",
        "    return ' '.join(words)\r\n",
        "\r\n",
        "actual = preprocess(['Half and Half 15 ounce of Grains'])\r\n",
        "assert actual == 'half and half grain', f'Preprocessing did not work, received \"{actual}\"'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614151072607
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting our data ready."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_json['ingredients'].apply(preprocess)\r\n",
        "Y_train = train_json['cuisine']\r\n",
        "print(X_train.size)\r\n",
        "print(Y_train.size)\r\n",
        "X_train.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614151078617
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Buid and train models"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multinomial Naive Bayes"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "\r\n",
        "vectorizer = CountVectorizer(min_df=0.05, max_df=0.90)\r\n",
        "\r\n",
        "# different document frequency\r\n",
        "vectorizer2 = CountVectorizer()\r\n",
        "X_train_vec = vectorizer2.fit_transform(X_train)\r\n",
        "\r\n",
        "mnb = MultinomialNB()\r\n",
        "mnb.fit(X_train_vec, Y_train)\r\n",
        "\r\n",
        "X_test = vectorizer2.transform([preprocess([\r\n",
        "        \"pork stew meat\",\r\n",
        "        \"salt\",\r\n",
        "        \"tomatoes\",\r\n",
        "        \"tomatillos\",\r\n",
        "        \"chile pepper\",\r\n",
        "        \"pepper\",\r\n",
        "        \"garlic\"\r\n",
        "        ]), preprocess([\r\n",
        "        \"pork stew meat\",\r\n",
        "        \"salt\",\r\n",
        "        \"tomatoes\",\r\n",
        "        \"tomatillos\",\r\n",
        "        \"chile pepper\",\r\n",
        "        \"pepper\",\r\n",
        "        \"garlic\"\r\n",
        "    ])])\r\n",
        "mnb.predict(X_test)\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614151079405
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump, load\r\n",
        "dump(mnb, 'cook.model')\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614151079513
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnb_loaded = load('cook.model')\r\n",
        "X_test = vectorizer2.transform([preprocess([\r\n",
        "      \"sugar\",\r\n",
        "      \"large egg yolks\",\r\n",
        "      \"grated lemon peel\",\r\n",
        "      \"rhubarb\",\r\n",
        "      \"cream\",\r\n",
        "      \"salt\",\r\n",
        "      \"ground cinnamon\",\r\n",
        "      \"golden brown sugar\",\r\n",
        "      \"all-purpose flour\",\r\n",
        "      \"sliced almonds\",\r\n",
        "      \"unsalted butter\"\r\n",
        "    ])])\r\n",
        "mnb.predict(X_test)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614151079726
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict results using our model based on naive bayes algorithm and write to file."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_json = pd.read_json('./test.json')\n",
        "test_json.head()\n",
        "\n",
        "test = test_json['ingredients'].apply(preprocess)\n",
        "test.head()\n",
        "testfinal = vectorizer2.transform(test)\n",
        "result = mnb.predict(testfinal)\n",
        "print(result)\n",
        "print(len(result))\n",
        "result_transformed = pd.DataFrame(result)\n",
        "result_with_ids = pd.concat([test_json['id'], result_transformed], join = 'outer', axis = 1)\n",
        "print(result_with_ids) \n",
        "result_with_ids.to_csv('result_vectorizer2.csv', index = False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['british' 'southern_us' 'italian' ... 'italian' 'cajun_creole' 'mexican']\n",
            "9944\n",
            "         id             0\n",
            "0     18009       british\n",
            "1     28583   southern_us\n",
            "2     41580       italian\n",
            "3     29752  cajun_creole\n",
            "4     35687       italian\n",
            "...     ...           ...\n",
            "9939  30246        french\n",
            "9940  36028   southern_us\n",
            "9941  22339       italian\n",
            "9942  42525  cajun_creole\n",
            "9943   1443       mexican\n",
            "\n",
            "[9944 rows x 2 columns]\n"
          ]
        }
      ],
      "execution_count": 107,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614170217084
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n",
        "Train a model based on logistic regression and write the prediction's results to file."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\").fit(X_train_vec, Y_train)\n",
        "clf = LogisticRegression(max_iter=1000).fit(X_train_vec, Y_train)\n",
        "result = clf.predict(testfinal)\n",
        "print(result)\n",
        "print(len(result))\n",
        "result_transformed = pd.DataFrame(result)\n",
        "result_with_ids = pd.concat([test_json['id'], result_transformed], join = 'outer', axis = 1)\n",
        "print(result_with_ids) \n",
        "result_with_ids.to_csv('result_logistic_regression.csv', index = False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614151111279
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGB Classifier\n",
        "Train a model based on an xgb classifier."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost\n",
        "print(xgboost.__version__)\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train_vec, Y_train)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614151183506
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get prediction using the xgb classifier model and write results to file."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.predict(testfinal)\n",
        "print(result)\n",
        "print(len(result))\n",
        "result_transformed = pd.DataFrame(result)\n",
        "result_with_ids = pd.concat([test_json['id'], result_transformed], join = 'outer', axis = 1)\n",
        "print(result_with_ids) \n",
        "result_with_ids.to_csv('result_xgbclassifier.csv', index = False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614151185117
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect a Data Lake:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Datastore\n",
        "ADLSGEN2_DATASTORE = 'stdatasciencelab'\n",
        "ADLSGEN2_ACCOUNT = 'stdatasciencelab'\n",
        "TENANT_ID = '022e4faf-c745-475a-be06-06b1e1c9e39d'\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "kv = ws.get_default_keyvault()\n",
        "CLIENT_ID = kv.get_secret('azureml-dls-appid')\n",
        "CLIENT_SECRET = kv.get_secret('azureml-dls-secret')\n",
        "\n",
        "adlsgen2_datastore = Datastore.register_azure_data_lake_gen2(\n",
        "    workspace=ws, \n",
        "    datastore_name=ADLSGEN2_DATASTORE, \n",
        "    account_name=ADLSGEN2_ACCOUNT,\n",
        "    filesystem='data',\n",
        "    tenant_id=TENANT_ID,\n",
        "    client_id=CLIENT_ID,\n",
        "    client_secret=CLIENT_SECRET)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614151188389
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dns.resolver\n",
        "\n",
        "ADLS_URL = 'stdatasciencelab.blob.core.windows.net'\n",
        "answers = dns.resolver.resolve(ADLS_URL)\n",
        "\n",
        "for entry in answers:\n",
        "    print('Server {srv} has IP address {ip}'.format(srv=ADLS_URL, ip=entry))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614151188448
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert json to json-line format "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_json.to_json(\"train.jl\", orient=\"records\", lines=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614151188782
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read in json line data for processing."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset, Datastore\n",
        "from azureml.data.datapath import DataPath\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "ds = ws.datastores['stdatasciencelab']\n",
        "\n",
        "df = Dataset.Tabular.from_json_lines_files(path = [(ds, '/train.jl')]).to_pandas_dataframe()\n",
        "df.head()\n",
        "\n",
        "# X_train = df['ingredients'].apply(preprocess)\n",
        "# Y_train = df['cuisine']\n",
        "# print(X_train.size)\n",
        "# print(Y_train.size)\n",
        "# X_train.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "      id      cuisine                                        ingredients\n0  10259        greek  [romaine lettuce, black olives, grape tomatoes...\n1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...\n2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...\n3  22213       indian                [water, vegetable oil, wheat, salt]\n4  13162       indian  [black pepper, shallots, cornflour, cayenne pe...",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cuisine</th>\n      <th>ingredients</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10259</td>\n      <td>greek</td>\n      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25693</td>\n      <td>southern_us</td>\n      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20130</td>\n      <td>filipino</td>\n      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22213</td>\n      <td>indian</td>\n      <td>[water, vegetable oil, wheat, salt]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13162</td>\n      <td>indian</td>\n      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615715558107
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# just some test code. can be deleted when not needed anymore\n",
        "\n",
        "datastore = Datastore.get(ws, datastore_name='stdatasciencelab')\n",
        "print(datastore)\n",
        "#dataset = Dataset.get_by_id(ws, id='stdatasciencelab')\n",
        "\n",
        "ds = Datastore.get(ws, datastore_name='stdatasciencelab')\n",
        "print(ds)\n",
        "\n",
        "# get the input dataset by ID\n",
        "#dataset = Dataset.get_by_id(ws, id='stdatasciencelab')\n",
        "\n",
        "# load the TabularDataset to pandas DataFrame\n",
        "#df = dataset.to_pandas_dataframe()\n",
        "\n",
        "df = Dataset.Tabular.from_json_lines_files(path = [(ds, '/train.jl')]).to_pandas_dataframe()\n",
        "X_train = df['ingredients'].apply(preprocess)\n",
        "Y_train = df['cuisine']\n",
        "\n",
        "vectorizer2 = CountVectorizer()\n",
        "X_train_vec = vectorizer2.fit_transform(X_train)\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(X_train_vec, Y_train)\n",
        "X_test = vectorizer2.transform(X_train)\n",
        "mnb.predict(X_test)\n",
        "\n",
        "my_model = load('cooking.pkl')\n",
        "\n",
        "my_model.predict(X_test)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Glossary of Azure ML\n",
        "\n",
        "#### Azure ML - General:\n",
        "\n",
        "- Azure ML Designer: Drag-and-Drop Interface (\"Designer\" in the sidebar to the left)\n",
        "- Azure ML Ops: comparable to Azure DevOps\n",
        "- Azure ML Pipelines: comparable to Azure Pipelines (\"Pipelines\" in the sidebar to the left)\n",
        "\n",
        "#### Data:\n",
        "In this sample project we retrieve our training data from a Data Lake, \n",
        "but of course there are many, many different options for Data according to your needs.\n",
        "In the sidebar to the left (\"Datastores\") you can inspect your current choice.\n",
        "\n",
        "#### Ways to run ML experiments:\n",
        "Your experiments as well as your finished models can be found in the sidebar to the left (\"Experiments\", and \"Models\" respectively)\n",
        "- Automated ML (\"Automated ML\" in the sidebar to the left): \n",
        "    - Either no-code or code-first. \n",
        "    - Easy to use, but limited capabilities - only pre-defined algorithms can be used.\n",
        "- Script Configuration: Provide your own Python scripts for ML experiments.\n",
        "\n",
        "#### Targets for model training:\n",
        "Those can be found in the sidebar to the left (\"Compute\")\n",
        "- Azure ML Compute Instance: For small-scale experiments\n",
        "- Azure ML Compute Cluster: For larger-scale experiments\n",
        "- You can also plug-in Non-ML targets of Azure:\n",
        "    - Azure Data Bricks\n",
        "    - Azure Data Lake Analytics\n",
        "    - Azure HD Insights\n",
        "    - Azure Batch\n",
        "\n",
        "#### Targets for model deployment:\n",
        "Those can be found in the sidebar to the left (\"Endpoints\" as well as \"Compute\")\n",
        "- Azure Container Instance: For small-scale experiments\n",
        "- Azure ML Compute Cluster: For larger-scale experiments\n",
        "- Azure Kubernetes Service: For largest-scale experiments"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automated ML\n",
        "Let Azure ML take care of the experiment's details - just choose your preferred configuration and you're good to go."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "automl_settings = {\n",
        "    \"iteration_timeout_minutes\": 10,\n",
        "    \"experiment_timeout_hours\": 0.3,\n",
        "    \"enable_early_stopping\": True,\n",
        "    \"primary_metric\": 'spearman_correlation',\n",
        "    \"featurization\": 'auto',\n",
        "    \"verbosity\": logging.INFO,\n",
        "    \"n_cross_validations\": 5\n",
        "}\n",
        "\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "automl_config = AutoMLConfig(task='regression',\n",
        "                             debug_log='automated_ml_errors.log',\n",
        "                             training_data=X_train_vec,\n",
        "                             label_column_name=\"ingredients\",\n",
        "                             **automl_settings)\n",
        "\n",
        "from azureml.core.experiment import Experiment\n",
        "experiment = Experiment(ws, \"cooking\")\n",
        "local_run = experiment.submit(automl_config, show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614151195129
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Experiments using your own scripts for training & deployment:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "experiment_name = 'cooking-naive-bayes'\n",
        "\n",
        "exp = Experiment(workspace=ws, name=experiment_name)"
      ],
      "outputs": [],
      "execution_count": 135,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614287344461
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We take advantage of an Azure ML Compute Cluster for running trainings of our ML model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "import os\n",
        "\n",
        "# choose a name for your cluster\n",
        "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpu-cluster\")\n",
        "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
        "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
        "\n",
        "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
        "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
        "\n",
        "\n",
        "if compute_name in ws.compute_targets:\n",
        "    compute_target = ws.compute_targets[compute_name]\n",
        "    if compute_target and type(compute_target) is AmlCompute:\n",
        "        print('found compute target. just use it. ' + compute_name)\n",
        "else:\n",
        "    print('creating a new compute target...')\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
        "                                                                min_nodes=compute_min_nodes,\n",
        "                                                                max_nodes=compute_max_nodes)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(\n",
        "        ws, compute_name, provisioning_config)\n",
        "\n",
        "    # can poll for a minimum number of nodes and for a specific timeout.\n",
        "    # if no min node count is provided it will use the scale settings for the cluster\n",
        "    compute_target.wait_for_completion(\n",
        "        show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
        "\n",
        "    # For a more detailed view of current AmlCompute status, use get_status()\n",
        "    print(compute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found compute target. just use it. cpu-cluster\n"
          ]
        }
      ],
      "execution_count": 137,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614287350365
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure the directory of your experiment's scripts"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "script_folder = os.path.join(os.getcwd(), \"sklearn-cooking\")\n",
        "os.makedirs(script_folder, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 136,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614287347618
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up your remote cluster's environment by installing required python packages."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# to install required packages\n",
        "env = Environment('cooking-test-env')\n",
        "cd = CondaDependencies.create(pip_packages=['azureml-dataset-runtime[pandas,fuse]', 'azureml-defaults', 'unidecode', 'nltk'], conda_packages=['scikit-learn==0.22.1'])\n",
        "\n",
        "env.python.conda_dependencies = cd\n",
        "\n",
        "# Register environment to re-use later\n",
        "env.register(workspace=ws)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 138,
          "data": {
            "text/plain": "{\n    \"databricks\": {\n        \"eggLibraries\": [],\n        \"jarLibraries\": [],\n        \"mavenLibraries\": [],\n        \"pypiLibraries\": [],\n        \"rcranLibraries\": []\n    },\n    \"docker\": {\n        \"arguments\": [],\n        \"baseDockerfile\": null,\n        \"baseImage\": \"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210104.v1\",\n        \"baseImageRegistry\": {\n            \"address\": null,\n            \"password\": null,\n            \"registryIdentity\": null,\n            \"username\": null\n        },\n        \"enabled\": false,\n        \"platform\": {\n            \"architecture\": \"amd64\",\n            \"os\": \"Linux\"\n        },\n        \"sharedVolumes\": true,\n        \"shmSize\": null\n    },\n    \"environmentVariables\": {\n        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n    },\n    \"inferencingStackVersion\": null,\n    \"name\": \"cooking-test-env\",\n    \"python\": {\n        \"baseCondaEnvironment\": null,\n        \"condaDependencies\": {\n            \"channels\": [\n                \"anaconda\",\n                \"conda-forge\"\n            ],\n            \"dependencies\": [\n                \"python=3.6.2\",\n                {\n                    \"pip\": [\n                        \"azureml-dataset-runtime[pandas,fuse]~=1.20.0\",\n                        \"azureml-defaults~=1.20.0\",\n                        \"unidecode\",\n                        \"nltk\"\n                    ]\n                },\n                \"scikit-learn==0.22.1\"\n            ],\n            \"name\": \"azureml_7015d1f629b952822f1bbd1f2d5c9fa3\"\n        },\n        \"condaDependenciesFile\": null,\n        \"interpreterPath\": \"python\",\n        \"userManagedDependencies\": false\n    },\n    \"r\": null,\n    \"spark\": {\n        \"packages\": [],\n        \"precachePackages\": true,\n        \"repositories\": []\n    },\n    \"version\": \"4\"\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 138,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614287359445
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is where the action happens - the train.py script gets executed in a training session. \n",
        "The top line writes the script's content in the folder we specified earlier. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/train.py\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import joblib\n",
        "from azureml.core import Workspace, Dataset, Datastore, Run\n",
        "from azureml.data.datapath import DataPath\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from utils import preprocess\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "run = Run.get_context()\n",
        "ws = run.experiment.workspace\n",
        "\n",
        "ds = Datastore.get(ws, datastore_name='stdatasciencelab')\n",
        "print(ds)\n",
        "\n",
        "df = Dataset.Tabular.from_json_lines_files(path = [(ds, '/train.jl')]).to_pandas_dataframe()\n",
        "X_train = df['ingredients'].apply(preprocess)\n",
        "Y_train = df['cuisine']\n",
        "\n",
        "vectorizer2 = CountVectorizer()\n",
        "X_train_vec = vectorizer2.fit_transform(X_train)\n",
        "\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(X_train_vec, Y_train)\n",
        "\n",
        "X_test = vectorizer2.transform(X_train)\n",
        "mnb.predict(X_test)\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "joblib.dump(value=mnb, filename='outputs/cooking.pkl')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /mnt/batch/tasks/shared/LS_root/mounts/clusters/stefan/code/Users/rainer/sklearn-cooking/train.py\n"
          ]
        }
      ],
      "execution_count": 139,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our model to work we need a preprocess-function, that's inside a utils.py file. We also copy it to the according folder."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy('utils.py', script_folder)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 140,
          "data": {
            "text/plain": "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/stefan/code/Users/rainer/sklearn-cooking/utils.py'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 140,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614287364941
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "The following code creates a scriptRunConfiguration."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "\n",
        "#args = ['--data-folder', mnist_file_dataset.as_mount(), '--regularization', 0.5]\n",
        "\n",
        "src = ScriptRunConfig(source_directory=script_folder,\n",
        "                      script='train.py', \n",
        "                      #arguments=args,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=env)"
      ],
      "outputs": [],
      "execution_count": 141,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614287369604
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Starts a run. After this code is executed, we can watch the cluster start-up and train our model. (\"Experiments\" in the sidebar to the left.)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = exp.submit(config=src)\n",
        "run"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 142,
          "data": {
            "text/plain": "Run(Experiment: cooking-naive-bayes,\nId: cooking-naive-bayes_1614287371_39111bb7,\nType: azureml.scriptrun,\nStatus: Starting)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>cooking-naive-bayes</td><td>cooking-naive-bayes_1614287371_39111bb7</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://ml.azure.com/experiments/cooking-naive-bayes/runs/cooking-naive-bayes_1614287371_39111bb7?wsid=/subscriptions/b33f0285-db27-4896-ac5c-df22004b0aba/resourcegroups/data-science/workspaces/data-science-playground\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 142,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614287374222
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As an alternative to the GUI-based \"Experiments\" I mentioned we can also have a widget provide the information regarding the current experiment training run."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "RunDetails(run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3af18fed06e8410482e5d5813079760a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/cooking-naive-bayes/runs/cooking-naive-bayes_1614287371_39111bb7?wsid=/subscriptions/b33f0285-db27-4896-ac5c-df22004b0aba/resourcegroups/data-science/workspaces/data-science-playground\", \"run_id\": \"cooking-naive-bayes_1614287371_39111bb7\", \"run_properties\": {\"run_id\": \"cooking-naive-bayes_1614287371_39111bb7\", \"created_utc\": \"2021-02-25T21:09:33.804422Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"3a05a9e3-d794-449a-b7f6-86cce795da9e\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-02-25T21:16:54.138041Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_b94b926318a0e240aef62c0d1b5e2f89693f4ed8ed58014434568cc330e24b29_d.txt\": \"https://stdatascienceplayground.blob.core.windows.net/azureml/ExperimentRun/dcid.cooking-naive-bayes_1614287371_39111bb7/azureml-logs/55_azureml-execution-tvmps_b94b926318a0e240aef62c0d1b5e2f89693f4ed8ed58014434568cc330e24b29_d.txt?sv=2019-02-02&sr=b&sig=ram6xtz2Ie4nEbBVhPtI0LH0qnDPjsScsFVEThOW6j8%3D&st=2021-02-25T21%3A06%3A47Z&se=2021-02-26T05%3A16%3A47Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_b94b926318a0e240aef62c0d1b5e2f89693f4ed8ed58014434568cc330e24b29_d.txt\": \"https://stdatascienceplayground.blob.core.windows.net/azureml/ExperimentRun/dcid.cooking-naive-bayes_1614287371_39111bb7/azureml-logs/65_job_prep-tvmps_b94b926318a0e240aef62c0d1b5e2f89693f4ed8ed58014434568cc330e24b29_d.txt?sv=2019-02-02&sr=b&sig=bLna1RLiiq95RI5PrV4b1Ykku1ry0ASAshS%2FJCNtdcc%3D&st=2021-02-25T21%3A06%3A47Z&se=2021-02-26T05%3A16%3A47Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://stdatascienceplayground.blob.core.windows.net/azureml/ExperimentRun/dcid.cooking-naive-bayes_1614287371_39111bb7/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=7FoNQMa7jXzZz7GsiSf3ivXIAysGu8me63w96UlCLvc%3D&st=2021-02-25T21%3A06%3A47Z&se=2021-02-26T05%3A16%3A47Z&sp=r\", \"azureml-logs/75_job_post-tvmps_b94b926318a0e240aef62c0d1b5e2f89693f4ed8ed58014434568cc330e24b29_d.txt\": \"https://stdatascienceplayground.blob.core.windows.net/azureml/ExperimentRun/dcid.cooking-naive-bayes_1614287371_39111bb7/azureml-logs/75_job_post-tvmps_b94b926318a0e240aef62c0d1b5e2f89693f4ed8ed58014434568cc330e24b29_d.txt?sv=2019-02-02&sr=b&sig=A1i5XOruN%2BthrifzEYYXsW3%2BXJe9EZbbBHR0nio8%2FC0%3D&st=2021-02-25T21%3A06%3A47Z&se=2021-02-26T05%3A16%3A47Z&sp=r\", \"azureml-logs/process_info.json\": \"https://stdatascienceplayground.blob.core.windows.net/azureml/ExperimentRun/dcid.cooking-naive-bayes_1614287371_39111bb7/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=sP2Gcmj2eIGDhQeH6k%2BAdq1CcCuF%2BFSkwUP4KeIjRBQ%3D&st=2021-02-25T21%3A06%3A47Z&se=2021-02-26T05%3A16%3A47Z&sp=r\", \"azureml-logs/process_status.json\": \"https://stdatascienceplayground.blob.core.windows.net/azureml/ExperimentRun/dcid.cooking-naive-bayes_1614287371_39111bb7/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=wVWX1eDYOt%2BB23DBXOoxZP59OY9pK0CoRTutJ8ShUmM%3D&st=2021-02-25T21%3A06%3A47Z&se=2021-02-26T05%3A16%3A47Z&sp=r\", \"logs/azureml/104_azureml.log\": \"https://stdatascienceplayground.blob.core.windows.net/azureml/ExperimentRun/dcid.cooking-naive-bayes_1614287371_39111bb7/logs/azureml/104_azureml.log?sv=2019-02-02&sr=b&sig=wEJBGV2YzQY1iUFLwk5rqEShUVknTcTfkfz7lEenmtI%3D&st=2021-02-25T21%3A06%3A47Z&se=2021-02-26T05%3A16%3A47Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://stdatascienceplayground.blob.core.windows.net/azureml/ExperimentRun/dcid.cooking-naive-bayes_1614287371_39111bb7/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=CcC%2FsGxpqKubpT1JhZidDNeg%2FhrsoeMm992dTTzXl4w%3D&st=2021-02-25T21%3A06%3A47Z&se=2021-02-26T05%3A16%3A47Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://stdatascienceplayground.blob.core.windows.net/azureml/ExperimentRun/dcid.cooking-naive-bayes_1614287371_39111bb7/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=vABpjnnnzfhZfPmKua2g3dQYLCWMDiI5jcVm7LrsHs4%3D&st=2021-02-25T21%3A06%3A47Z&se=2021-02-26T05%3A16%3A47Z&sp=r\", \"logs/azureml/dataprep/engine_spans_l_4fe56a55-8aab-4a1c-9300-2711c2feb0c0.jsonl\": \"https://stdatascienceplayground.blob.core.windows.net/azureml/ExperimentRun/dcid.cooking-naive-bayes_1614287371_39111bb7/logs/azureml/dataprep/engine_spans_l_4fe56a55-8aab-4a1c-9300-2711c2feb0c0.jsonl?sv=2019-02-02&sr=b&sig=EBT5I5uuZIjMfPGbFmtsqxQidx5TSS%2Fi9NTca50cdYU%3D&st=2021-02-25T21%3A06%3A47Z&se=2021-02-26T05%3A16%3A47Z&sp=r\", \"logs/azureml/dataprep/python_span_l_4fe56a55-8aab-4a1c-9300-2711c2feb0c0.jsonl\": \"https://stdatascienceplayground.blob.core.windows.net/azureml/ExperimentRun/dcid.cooking-naive-bayes_1614287371_39111bb7/logs/azureml/dataprep/python_span_l_4fe56a55-8aab-4a1c-9300-2711c2feb0c0.jsonl?sv=2019-02-02&sr=b&sig=WFv9ezQc0pY7CFpz6%2FfuoM4XnC8UZkA3QKtjedza69Q%3D&st=2021-02-25T21%3A06%3A47Z&se=2021-02-26T05%3A16%3A47Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://stdatascienceplayground.blob.core.windows.net/azureml/ExperimentRun/dcid.cooking-naive-bayes_1614287371_39111bb7/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=fINXbd6sJ84UW%2Fz6jEj%2BR25cRLFrIfkPk3ksYiKZ7e0%3D&st=2021-02-25T21%3A06%3A47Z&se=2021-02-26T05%3A16%3A47Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://stdatascienceplayground.blob.core.windows.net/azureml/ExperimentRun/dcid.cooking-naive-bayes_1614287371_39111bb7/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=906e13adX60DaBhygixz6RrmMlORClWXTEtlgwUkzT8%3D&st=2021-02-25T21%3A06%3A47Z&se=2021-02-26T05%3A16%3A47Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"logs/azureml/dataprep/engine_spans_l_4fe56a55-8aab-4a1c-9300-2711c2feb0c0.jsonl\", \"logs/azureml/dataprep/python_span_l_4fe56a55-8aab-4a1c-9300-2711c2feb0c0.jsonl\"], [\"azureml-logs/55_azureml-execution-tvmps_b94b926318a0e240aef62c0d1b5e2f89693f4ed8ed58014434568cc330e24b29_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_b94b926318a0e240aef62c0d1b5e2f89693f4ed8ed58014434568cc330e24b29_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_b94b926318a0e240aef62c0d1b5e2f89693f4ed8ed58014434568cc330e24b29_d.txt\"], [\"logs/azureml/104_azureml.log\"]], \"run_duration\": \"0:07:20\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"2021-02-25 21:15:58,626|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2021-02-25 21:15:58,628|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2021-02-25 21:15:58,636|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2021-02-25 21:15:58,637|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-02-25 21:15:58,997|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f8925487d08> for run source azureml.scriptrun\\n2021-02-25 21:15:59,000|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-02-25 21:15:59,009|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-02-25 21:15:59,009|azureml.core.authentication|DEBUG|Time to expire 1814013.990246 seconds\\n2021-02-25 21:15:59,010|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-02-25 21:15:59,010|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2021-02-25 21:15:59,048|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:15:59,048|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:15:59,048|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:15:59,048|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:15:59,049|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:15:59,049|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:15:59,049|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:15:59,095|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-02-25 21:15:59,095|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-02-25 21:15:59,210|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-02-25 21:15:59,211|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '3a05a9e3-d794-449a-b7f6-86cce795da9e', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-02-25 21:15:59,212|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-02-25 21:15:59,213|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2021-02-25 21:15:59,214|azureml.WorkerPool|DEBUG|[START]\\n2021-02-25 21:15:59,214|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-02-25 21:15:59,214|azureml.RunStatusContext|DEBUG|[START]\\n2021-02-25 21:15:59,215|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-02-25 21:15:59,215|azureml.MetricsClient|DEBUG|[START]\\n2021-02-25 21:15:59,215|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-02-25 21:15:59,215|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-02-25 21:15:59,215|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-02-25 21:15:59,215|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/data-science-playground/azureml/cooking-naive-bayes_1614287371_39111bb7/mounts/workspaceblobstore/azureml/cooking-naive-bayes_1614287371_39111bb7\\n2021-02-25 21:15:59,215|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-02-25 21:15:59,215|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/data-science-playground/azureml/cooking-naive-bayes_1614287371_39111bb7/mounts/workspaceblobstore/azureml/cooking-naive-bayes_1614287371_39111bb7\\n2021-02-25 21:16:00,950|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-02-25 21:16:00,951|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:16:00,951|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:16:00,951|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:16:00,952|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:16:00,952|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:16:00,952|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:16:00,952|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:16:00,986|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-02-25 21:16:00,987|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-02-25 21:16:01,050|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-02-25 21:16:01,051|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '3a05a9e3-d794-449a-b7f6-86cce795da9e', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-02-25 21:16:01,051|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-02-25 21:16:01,052|azureml.data.datastore_client|DEBUG|Getting datastore: stdatasciencelab\\n2021-02-25 21:16:01,052|azureml.data.datastore_client|INFO|<azureml.core.authentication.AzureMLTokenAuthentication object at 0x7f8927670390>\\n2021-02-25 21:16:01,452|azureml.data.datastore_client|DEBUG|Received DTO from the datastore service\\n2021-02-25 21:16:01,505|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-02-25 21:16:01,506|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:16:01,507|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:16:01,508|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:16:01,508|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:16:01,510|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:16:01,514|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:16:01,515|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://westeurope.experiments.azureml.net.\\n2021-02-25 21:16:29,001|azureml.core.authentication|DEBUG|Time to expire 1813983.998914 seconds\\n2021-02-25 21:16:29,218|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-02-25 21:16:29,218|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/data-science-playground/azureml/cooking-naive-bayes_1614287371_39111bb7/mounts/workspaceblobstore/azureml/cooking-naive-bayes_1614287371_39111bb7\\n2021-02-25 21:16:29,218|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/data-science-playground/azureml/cooking-naive-bayes_1614287371_39111bb7/mounts/workspaceblobstore/azureml/cooking-naive-bayes_1614287371_39111bb7 to /mnt/batch/tasks/shared/LS_root/jobs/data-science-playground/azureml/cooking-naive-bayes_1614287371_39111bb7/mounts/workspaceblobstore/azureml/cooking-naive-bayes_1614287371_39111bb7\\n2021-02-25 21:16:29,218|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/data-science-playground/azureml/cooking-naive-bayes_1614287371_39111bb7/mounts/workspaceblobstore/azureml/cooking-naive-bayes_1614287371_39111bb7\\n2021-02-25 21:16:29,218|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2021-02-25 21:16:29,219|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2021-02-25 21:16:29,219|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-02-25 21:16:29,219|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-02-25 21:16:29,219|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-02-25 21:16:29,219|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-02-25 21:16:29,219|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-02-25 21:16:29,219|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-02-25 21:16:29,220|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-02-25 21:16:29,220|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-02-25 21:16:29,220|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-02-25 21:16:29,220|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-02-25 21:16:29,220|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-02-25 21:16:29,220|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-02-25 21:16:29,220|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-02-25 21:16:29,221|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-02-25 21:16:29,221|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-02-25 21:16:29,221|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-02-25 21:16:29,221|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-02-25 21:16:29,221|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-02-25 21:16:29,221|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-02-25 21:16:29,221|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-02-25 21:16:29,312|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-02-25 21:16:29,313|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2021-02-25 21:16:29,313|azureml.MetricsClient|DEBUG|[STOP]\\n2021-02-25 21:16:29,313|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-02-25 21:16:29,313|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-02-25 21:16:29,313|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-02-25 21:16:29,314|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-02-25 21:16:29,314|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-02-25 21:16:29,314|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-02-25 21:16:29,314|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-02-25 21:16:29,314|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-02-25 21:16:29,314|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-02-25 21:16:29,314|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-02-25 21:16:29,314|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-02-25 21:16:29,314|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-02-25 21:16:29,314|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-02-25 21:16:29,314|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-02-25 21:16:29,597|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-02-25 21:16:29,597|azureml.RunStatusContext|DEBUG|[STOP]\\n2021-02-25 21:16:29,598|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-02-25 21:16:29,598|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-02-25 21:16:29,598|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-02-25 21:16:29,598|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-02-25 21:16:29,598|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-02-25 21:16:29,598|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-02-25 21:16:29,598|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-02-25 21:16:29,598|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-02-25 21:16:29,598|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-02-25 21:16:29,598|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-02-25 21:16:29,598|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-02-25 21:16:29,599|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-02-25 21:16:29,599|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-02-25 21:16:29,599|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-02-25 21:16:29,678|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-02-25 21:16:29,678|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-02-25 21:16:29,678|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-02-25 21:16:29,678|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-02-25 21:16:29,679|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-02-25 21:16:29,679|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-02-25 21:16:29,679|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-02-25 21:16:29,679|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-02-25 21:16:29,679|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-02-25 21:16:29,679|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-02-25 21:16:29,679|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-02-25 21:16:29,679|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-02-25 21:16:29,680|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-02-25 21:16:29,680|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-02-25 21:16:29,680|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-02-25 21:16:29,680|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-02-25 21:16:29,680|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-02-25 21:16:29,680|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-02-25 21:16:29,680|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-02-25 21:16:29,680|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-02-25 21:16:29,680|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-02-25 21:16:29,745|azureml._SubmittedRun#cooking-naive-bayes_1614287371_39111bb7.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-02-25 21:16:29,745|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2021-02-25 21:16:29,745|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2021-02-25 21:16:29,745|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2021-02-25 21:16:29,746|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.20.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 143,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614287379026
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On Completion we can get metadata of the run."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run.wait_for_completion(show_output=False)\n",
        "print(run.get_metrics())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n"
          ]
        }
      ],
      "execution_count": 144,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614287827351
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can access the run's outputs folder:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(run.get_file_names())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['azureml-logs/55_azureml-execution-tvmps_90564ec88d84d5aaefebf9748d8268e12f853c10134e3482a4681949f5161cf7_d.txt', 'azureml-logs/65_job_prep-tvmps_90564ec88d84d5aaefebf9748d8268e12f853c10134e3482a4681949f5161cf7_d.txt', 'azureml-logs/70_driver_log.txt', 'azureml-logs/75_job_post-tvmps_90564ec88d84d5aaefebf9748d8268e12f853c10134e3482a4681949f5161cf7_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/104_azureml.log', 'logs/azureml/dataprep/backgroundProcess.log', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log', 'logs/azureml/dataprep/engine_spans_l_0a55da96-2682-4450-ba75-88752d173b1f.jsonl', 'logs/azureml/dataprep/python_span_l_0a55da96-2682-4450-ba75-88752d173b1f.jsonl', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/cooking.pkl']\n"
          ]
        }
      ],
      "execution_count": 124,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614173443531
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can also register our finished model so others can use it, too. Finally we deploy it to an Azure Container Instance. \n",
        "As we use sci-kit learn, Azure ML automatically takes care of creating the container."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\n",
        "from datetime import datetime\n",
        "\n",
        "dt = datetime.now()\n",
        "# register model\n",
        "model = run.register_model(model_name='cooking_naivebayes_' + dt.strftime('%d%m%Y_%H%M%S'),\n",
        "                           model_path='outputs/cooking.pkl',\n",
        "                           model_framework=Model.Framework.SCIKITLEARN,\n",
        "                           model_framework_version='0.19.1',\n",
        "                           resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=0.5))\n",
        "\n",
        "# deploy model\n",
        "web_service = Model.deploy(ws, \"scikit-learn-service\", [model])\n",
        "\n",
        "print(model.name, model.id, model.version, sep='\\t')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cooking_naivebayes_24022021_135814\tcooking_naivebayes_24022021_135814:1\t1\n"
          ]
        }
      ],
      "execution_count": 132,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614175099152
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For manual deployment, we need to provide an entry script (entry.py, also listed here in our notebook) with two functions init and run."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'cooking.pkl')\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "def run(data):\n",
        "    try:\n",
        "        data = np.array(json.loads(data))\n",
        "        result = model.predict(data)\n",
        "        # You can return any data type, as long as it is JSON serializable.\n",
        "        return result.tolist()\n",
        "    except Exception as e:\n",
        "        error = str(e)\n",
        "        return error"
      ],
      "outputs": [],
      "execution_count": 145,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614288720862
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also need an inference config:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.environment import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "\n",
        "env = Environment.get(ws, \"AzureML-Minimal\").clone(env)\n",
        "\n",
        "for pip_package in [\"scikit-learn\"]:\n",
        "    env.python.conda_dependencies.add_pip_package(pip_package)\n",
        "\n",
        "inference_config = InferenceConfig(entry_script='entry.py',\n",
        "                                    environment=env)"
      ],
      "outputs": [],
      "execution_count": 149,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614288856593
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pick web service target and start deployment."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import LocalWebservice, Webservice, AciWebservice\n",
        "\n",
        "#deployment_config = LocalWebservice.deploy_configuration(port=8890)\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
        "service = Model.deploy(ws, \"myservice\", [model], inference_config, deployment_config)\n",
        "service.wait_for_deployment(show_output = True)\n",
        "print(service.state)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}